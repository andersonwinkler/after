#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Jun 28 15:11:38 2025

@author: winkler
"""

import argparse
import numpy as np
import h5py

import lib

def create_empty_hdf5(filename, rows, cols, dtype=np.float64):
    """Create empty HDF5 matrix file with compression."""
    with h5py.File(filename, 'w') as f:
        # Column-optimized chunking
        chunk_cols = min(64, cols)
        chunks     = (rows, chunk_cols)        
        f.create_dataset(
            'matrix',
            shape            = (rows, cols),
            dtype            = dtype,
            chunks           = chunks,
            compression      = 'gzip',
            compression_opts = 9,
            shuffle          = True )

if __name__ == "__main__":

    # Argument parser
    parser = argparse.ArgumentParser(
                        description=\
                        'Smooth data on the surface of a mesh using geodesic distances.',
                        epilog=\
                        'Anderson M. Winkler / UTRGV / Jul 2025 / https://brainder.org')
    # Options to create distance matrix
    parser.add_argument('--method',
                        help='Method to compute distances. Can be "mitchell", "crane", or "dijkstra".',
                        type=str, required=False, default='crane')
    parser.add_argument('--surf',
                        help='Surface to compute geodesic distances, each vertex to each other vertex.',
                        type=str, required=False, default=None)
    parser.add_argument('--outdist', dest='outdist',
                        help="Path to the file to store distance matrix (in HDF5 format).",
                        type=str, required=False, default=None)
    parser.add_argument('--maxfwhm', dest='maxfwhm',
                        help="Maximum intended FWHM with which the matrix of distances will be used.",
                        type=float, required=False, default=30)
    # Options to smooth data
    parser.add_argument('--indist', dest='indist',
                        help="Path to the file with distance matrix stored (in HDF5 format).",
                        type=str, required=False, default=None)
    parser.add_argument('--in', dest='infile',
                        help="Path to the file with data to be smoothed.",
                        type=str, required=False, default=None)
    parser.add_argument('--it', dest='intype',
                        help="Input type (file format)",
                        type=str, required=False, default='curv')
    parser.add_argument('--out', dest='outfile',
                        help="Path to the file to be created with smoothed data.",
                        type=str, required=False, default=None)
    parser.add_argument('--ot', dest='outtype',
                        help="Output type (file format)",
                        type=str, required=False, default='curv')
    parser.add_argument('--fwhm', dest='fwhm',
                        help="FWHM to smooth the data.",
                        type=float, required=False, default=10)
    # Show a nice progress bar (only use in interactive sessions)
    parser.add_argument('--progress',
                        help='Show a progress bar (avoid in headless systems)',
                        action='store_true', required=False, default=False)
    args = parser.parse_args()
    
    # Sanity check
    if args.indist is not None and args.outdist is not None:
        raise ValueError('Error: Cannot use --indist together with --outdist.')
    if args.indist is None and args.outdist is None:
        raise ValueError('Error: Missing --outdist.')
    
    create = True
    apply  = False
    
    if   create and not apply:

        # Read surface file
        vtx, fac, _, _ = lib.io.read_surf(args.surf)
        nV = vtx.shape[0]
        
        # Create empty HDF5 to store the distance matrix
        create_empty_hdf5(args.outdist, nV, nV, dtype=np.float32)
        
        if args.method.lower() in ['mitchell', 'exact', 'mmp']:
            # Use the method by Mitchell, Mount, and Papadimitriou (1987).
            # This is exact but very slow for meshes with more than a few hundred vertices.
            import gdist
            
            # Convert to native byte order
            vtx_native = vtx.astype(np.float64, order='C', copy=True)
            fac_native = fac.astype(np.int32,   order='C', copy=True)
            vtx_native = np.ascontiguousarray(vtx_native, dtype=np.float64)
            fac_native = np.ascontiguousarray(fac_native, dtype=np.int32)
            
            # How far to keep computing distances
            if args.maxfwhm is None:
                maxdist = np.inf
            else:
                maxdist = 4 * args.maxfwhm / np.sqrt(8*np.log(2)) # 4*sigma

            # Open the HDF5 file for writing, then iterate over vertices to
            # compute the distances and storing
            with h5py.File(args.outdist, 'r+') as f:
                for v in range(nV):
                    f['matrix'][:,v] = gdist.compute_gdist(vtx_native, fac_native,
                                                           max_distance   = maxdist,
                                                           source_indices = np.array([v],
                                                           dtype          = np.int32))

        elif args.method.lower() in ['crane', 'fast', 'approximate', 'heat', 'cww']:
            # Use the method by Crane, Weischedel, and Wardetzky (2013), which
            # uses heat diffusion for a much faster approximation, that is best for
            # finely resolved meshes
            import potpourri3d as pp3d
            solver = pp3d.MeshHeatMethodDistanceSolver(vtx, fac, t_coef=1.0, use_robust=True)
            
            # Open the HDF5 file for writing, then iterate over vertices to
            # compute the distances and storing
            with h5py.File(args.outdist, 'r+') as f:
                for v in range(nV):
                    f['matrix'][:,v] = solver.compute_distance(v)        

    elif apply and not create:
        # Smooth data by applying an existing matrix of distances
        import scipy as sp
        
        # Read input data
        data, _ = lib.io.read_curv(args.infile, is_ascii=False)
        sigma   = args.fwhm / np.sqrt(8*np.log(2))
        nV      = data.shape[0]
        
        # With the HDF5 file open, smooth each vertex
        sdata   = np.zeros(data.shape)
        with h5py.File(args.indist,'r') as f:
            for v in range(nV):
                dist = f['matrix'][:,v]
                dist[dist==0] = np.inf
                dist[v]  = 0
                height   = sp.stats.norm.pdf(dist, loc=0, scale=sigma)
                height   = height/height.sum()
                sdata[v] = np.sum(data * height)

        # Save smoothed data
        lib.io.write_curv(args.out, sdata)
        
    elif create and apply:
        import scipy as sp
        
        # Read surface file
        vtx, fac, _, _ = lib.io.read_surf(args.surf)
        nV = vtx.shape[0]
        
        # Read input data
        data, _ = lib.io.read_curv(args.infile, is_ascii=False)
        sigma   = args.fwhm / np.sqrt(8*np.log(2))
        nV      = data.shape[0]
        
        # Create empty HDF5 to store the distance matrix
        create_empty_hdf5(args.outdist, nV, nV, dtype=np.float32)
        
        if args.method.lower() in ['mitchell', 'exact', 'mmp']:
            # Use the method by Mitchell, Mount, and Papadimitriou (1987).
            # This is exact but very slow for meshes with more than a few hundred vertices.
            import gdist
            
            # Convert to native byte order
            vtx_native = vtx.astype(np.float64, order='C', copy=True)
            fac_native = fac.astype(np.int32,   order='C', copy=True)
            vtx_native = np.ascontiguousarray(vtx_native, dtype=np.float64)
            fac_native = np.ascontiguousarray(fac_native, dtype=np.int32)
            
            # How far to keep computing distances
            if args.maxfwhm is None:
                maxdist = np.inf
            else:
                maxdist = 4 * args.maxfwhm / np.sqrt(8*np.log(2)) # 4*sigma

            # Open the HDF5 file for writing, then iterate over vertices to
            # compute the distances and storing
            sdata   = np.zeros(data.shape)
            with h5py.File(args.outdist, 'r+') as f:
                for v in range(nV):
                    dist = gdist.compute_gdist(vtx_native, fac_native,
                                               max_distance   = maxdist,
                                               source_indices = np.array([v],
                                               dtype          = np.int32))
                    f['matrix'][:,v] = dist
                    dist[dist==0] = np.inf
                    dist[v]  = 0
                    height   = sp.stats.norm.pdf(dist, loc=0, scale=sigma)
                    height   = height/height.sum()
                    sdata[v] = np.sum(data * height)

        elif args.method.lower() in ['crane', 'fast', 'approximate', 'heat', 'cww']:
            # Use the method by Crane, Weischedel, and Wardetzky (2013), which
            # uses heat diffusion for a much faster approximation, that is best for
            # finely resolved meshes
            import potpourri3d as pp3d
            solver = pp3d.MeshHeatMethodDistanceSolver(vtx, fac, t_coef=1.0, use_robust=True)
            
            # Open the HDF5 file for writing, then iterate over vertices to
            # compute the distances and storing
            sdata   = np.zeros(data.shape)
            with h5py.File(args.outdist, 'r+') as f:
                for v in range(nV):
                    dist = solver.compute_distance(v)
                    f['matrix'][:,v] = dist
                    height   = sp.stats.norm.pdf(dist, loc=0, scale=sigma)
                    height   = height/height.sum()
                    sdata[v] = np.sum(data * height)

        # Save smoothed data
        lib.io.write_curv(args.out, sdata)